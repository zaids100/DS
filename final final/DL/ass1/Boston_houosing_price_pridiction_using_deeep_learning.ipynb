{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1665f27-9600-4493-a3cb-5b33d5254ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and visualization\n",
    "# !pip install tensorflow numpy pandas matplotlib scikit-learn\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# X_trian feature   x_test = target field i.e price priditciton \n",
    "(X_train , y_train), (X_test , y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "                                            path = 'boston_housing_npz',\n",
    "                                            test_split = 0.2,\n",
    "                                            seed = 42\n",
    "                                        )\n",
    "\n",
    "# Checking the data shape and type\n",
    "(X_train.shape, type(X_train)), (X_test.shape, type(X_test)), (y_train.shape, type(y_train)), (y_test.shape, type(y_test)),\n",
    "\n",
    "# Converting Data to DataFrame  \n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "# Preview the training data  show first 10 df \n",
    "X_train_df.head(10)\n",
    "\n",
    "# View summary of datasets  \n",
    "X_train_df.info()\n",
    "print('_'*40)\n",
    "y_train_df.info()\n",
    "\n",
    "# distribution of numerical feature values across the samples  =Provides mean, std, min, max, and quartile values for each feature column\n",
    "X_train_df.describe()\n",
    "\n",
    "# Create column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    ")\n",
    "\n",
    "# Normalization and data type change  =Converts all arrays to float32 for model compatibility.\n",
    "X_train = ct.fit_transform(X_train).astype('float32')\n",
    "X_test = ct.transform(X_test).astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Distribution of X_train feature values after normalization\n",
    "pd.DataFrame(X_train).describe()\n",
    "\n",
    "# Reserve data for validation  Further splits training data:\n",
    "#90% becomes training\n",
    "#10% becomes validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape\n",
    "\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "# Set random seed  sset seed for reproducibility.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Building the model\n",
    "#Defines a 3-layer neural network with ReLU activation for hidden layers and no activation for output (regression).\n",
    "model = tf.keras.Sequential([\n",
    "  Input(shape=(X_train.shape[1],), name='Input'),\n",
    "  tf.keras.layers.Dense(units=10, activation='relu', name='Dense_1'),\n",
    "  tf.keras.layers.Dense(units=100, activation='relu', name='Dense_2'),\n",
    "  tf.keras.layers.Dense(units=1, name='Prediction')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.01),#RMSprop with learning rate of 0.01.\n",
    "    metrics=['mse']#Tracks Mean Squared Error during training.\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val)#Validates performance on the validation set.\n",
    ")\n",
    "\n",
    "# Preview the mean value of training and validation data\n",
    "y_train.mean(), y_val.mean()\n",
    "\n",
    "# Evaluate the model on the test data  Tests model on unseen data and prints loss and MSE.\n",
    "\n",
    "\n",
    "print(\"Evaluation on Test data \\n\")\n",
    "loss, mse = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"\\nModel loss on test set: {loss}\")\n",
    "print(f\"Model mean squared error on test set: {(mse):.2f}\")\n",
    "\n",
    "# Plot the loss curves    Helps detect overfitting or underfitting.\n",
    "pd.DataFrame(history.history).plot(figsize=(6, 4), xlabel=\"Epochs\", ylabel=\"Loss\", title='Loss Curves')\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# View the first prediction\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397c1cd-0c4d-4cb0-8bf9-e76757c0de14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
